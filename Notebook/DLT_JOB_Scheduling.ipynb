{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7103de92-7abd-4e9d-aec7-87b130014c72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Creating the Workflow\n",
    "## JSON Based \n",
    "\n",
    "{\n",
    "    \"id\": \"6cfba946-8fbc-48b0-92bb-351d732c1c06\",\n",
    "    \"pipeline_type\": \"WORKSPACE\",\n",
    "    \"development\": true,\n",
    "    \"continuous\": false,\n",
    "    \"channel\": \"CURRENT\",\n",
    "    \"photon\": true,\n",
    "    \"libraries\": [\n",
    "        {\n",
    "            \"notebook\": {\n",
    "                \"path\": \"/Users/***************************/Real-Time-POS/Notebook/Data-Consumer(Bronze-To-Silver)\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"notebook\": {\n",
    "                \"path\": \"/Users/**************/Real-Time-POS/Notebook/Silver_To_Gold\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"name\": \"Real-Time-POS\",\n",
    "    \"serverless\": true,\n",
    "    \"catalog\": \"workspace\",\n",
    "    \"schema\": \"pos_dlt\",\n",
    "    \"data_sampling\": false\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fdbabdc5-6fd6-4bbe-b2f7-a34fa56072c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "*** Steps ***\n",
    "\n",
    "1. **Data-Generation**\n",
    "   - Create UI Based JOB scheduled to run every 2 mins to push data to Kafka Cluster and S3 bucket.\n",
    "   - ![](https://raw.githubusercontent.com/amar5075kumar/Real-Time-POS/refs/heads/main/Doc/Data_Generation_Job.png)\n",
    "\n",
    "2. **DLT Table Creation**\n",
    "   - **raw_inventory_change**: Streaming table reads data from Kafka.\n",
    "   - **item**: Reads data from S3 file item.\n",
    "   - **inventory_snapshot**: Snapshot data from S3 produced using data generation.\n",
    "   - **inventory_change**: Transformed table created from raw_inventory_change table.\n",
    "   - **inventory_change_type**: Fixed table used for simulation purposes.\n",
    "   - **Latest Inventory Snapshot**: Extracts the latest inventory snapshot using Merge.\n",
    "   - **Store**: Fixed table stored in S3.\n",
    "   - **current_inventory**: Created using all other tables and triggered every 5 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21210dba-959f-48e3-b724-1e9db3dd536b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "*** Monitoring the DLT Workflow ***\n",
    "![](https://github.com/amar5075kumar/Real-Time-POS/blob/main/Doc/Creating_DLT.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "050a68a6-9f73-44f0-bdd3-346597675c88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DLT_JOB_Scheduling",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
